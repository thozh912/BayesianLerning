---
title: "Computer Lab 4"
author: "Andrea Bruzzone, Thomas Zhang"
date: "2016 M05 18"
output: pdf_document
---

## Assignment 1

We do a `glm()` fit and obtain the maximum liklihood estimator of $\beta$ in the Poisson regression model for the eBay data.

```{r,echo=FALSE,message=FALSE,warning=FALSE}
library(stats)
library(mvtnorm)
library(coda)
ebaydata <- read.table("eBayNumberOfBidderData.dat", header = TRUE)
#head(ebaydata)
ebaydata <- ebaydata[,-2]
glmresult <- glm(nBids ~.-1 ,  family = "poisson", ebaydata)
#summary(glmresult)

#It looks like VerifyID, Sealed, MajBlem, LogBook and MinBidShare
#are significant predictors in this model.


paste("The maximum liklihood estimator of beta coefficients:")
glmresult$coefficients
```

Through the `summary.glm()` function, we can say that it looks like VerifyID, Sealed, MajBlem, LogBook and MinBidShare are significant predictors in this model.

Next, we do a Bayesian analysis of the Poisson regression with prior distribution $\beta \sim \mathcal{N}(\mathbf{0}, 100 \cdot (X'X)^{-1})$.
We know that we can use the `optim()` function to numerically fund the posterior mode $\tilde{\beta}$ and the Hessian $-J_{y,\tilde{\beta}}$ at that posterior mode. With these values we can approximate the posterior distribution as a multivariate normal distribution, $\beta|y \sim \mathcal{N}(\tilde{\beta}, J_{y,\tilde{\beta}}^{-1})$.

```{r,echo=FALSE}
X <- cbind(rep(1, nrow(ebaydata)),ebaydata[,-1])
LogPostPoisson <- function(betaVect,y,X){
  X <- as.matrix(X)
  nPara <- length(betaVect)
  linPred <- X%*% betaVect
  Loglik <- sum( y * linPred  - exp(linPred))
  Logprior <- dmvnorm(t(betaVect), rep(0,9), 
                      sigma = 100 * solve( t(X)%*%X ), log=TRUE)
  return(Loglik + Logprior)
}

initVal <- rep(0,9)
OptimResults<-optim(initVal,LogPostPoisson,gr=NULL,
                    y = ebaydata$nBids,X = X,method=c("BFGS"),
                    control=list(fnscale=-1),hessian=TRUE)
Jay <- -OptimResults$hessian
betatilde <- OptimResults$par
posteriordraw <- rmvnorm(1, mean = betatilde, sigma = solve(Jay))
paste("The posterior mode beta coefficients: ")
betatilde
paste("The hessian at the posterior mode: ")
OptimResults$hessian
paste("A posterior draw of beta: ")
posteriordraw
```

Now we simulate from the actual posterior of $\beta$ using the random walk Metropolis-Hanstings algorithm. We are going to use a multivariate normal density,  $\theta_{p}|\theta_{c} \sim \mathcal{N}(\theta_{c}, \tilde{c} \cdot \Sigma)$  as proposal density where $\Sigma = J_{y,\tilde{\beta}}^{-1}$ and $\tilde{c}$ is equal to 2.4 divided by the squre root of the number of parameters. 

```{r,echo=FALSE}
#Metropolis-Hastings Algorithm for any logpostfunc
outerfunc <- function(propdensity,c,innerfunc,...){
  nIter <-10000
  startmeanvector <- as.vector(propdensity[[1]])
  sigma <- as.matrix(propdensity[[2]])
  draws <- matrix(0,nrow = nIter,ncol = length(startmeanvector))
  draws[1,] <- startmeanvector
  for(i in 2:nIter){
    proposaldraw <- rmvnorm(1, mean = draws[i-1,],sigma = sigma)
    unifdraw <- runif(1)
    alpha <- min(1,exp(innerfunc(t(proposaldraw),...) - innerfunc(draws[i-1,],...)))
    
    if(unifdraw < alpha){
      draws[i,] <- proposaldraw
    }else{
      draws[i,] <- draws[i-1,]
    }
  }
  
  return(draws)
}

prior <- list(betatilde, solve(Jay)) 
c <- 2.4/sqrt(8)

mhresult <- outerfunc(prior,c,LogPostPoisson,
                      y = ebaydata$nBids , X = X)

paste("last iteration of M-H algorithm: ")
mhresult[dim(mhresult)[1],]
```

As it can be seen the draw from the M-H algorithm is very similar to the one found before.

We plot the traceplots for each beta coefficient and then we plot the histograms for the posterior distributions of $\phi_{j} = \exp{\beta_{j}}$.

```{r,echo=FALSE}
par(mfrow = c(2,2))
for(i in 1:dim(mhresult)[2]){
  plot(mhresult[,i],type="l",col=i,
       ylab = c("beta coef. no: ",i),xlab = "iteration")
}
effsizes <- effectiveSize(as.mcmc(mhresult))
paste("Effective sizes of the MCMC chains, 10000 iterations: ")
effsizes
burnins <- mhresult[1:1000,]
withoutburnins <- mhresult[1001:dim(mhresult)[1],]
phis <- exp(withoutburnins)
for(i in 1:dim(mhresult)[2]){
  hist(phis[,i], breaks = 100,col=i, main = c("Posterior dist. of phi coef. no: ",i),
       xlab = "phi value",border = "white")
}
```

From the traceplots we can see that all the $\beta$ values seem to converge. Anyways the effective samples size is only about 3.5%.

Finally we plot a histogram over the predictive distribution of poisson parameter $\lambda$ for the auction given in the lab instructions and calculate the probability that that auction will have zero bids.  
```{r,echo = FALSE}
newX <- c(1, 1, 1, 1, 0, 0, 0, 1, 0.5)

predictresult <- withoutburnins %*%as.matrix(newX)
predictpoissonpar <- exp(predictresult)
par(mfrow = c(1,1))
hist(predictpoissonpar,breaks = 50)
#predictprob <- ppois(0.5,lambda = predictpoissonpar)
predictprob <- rpois(10000,lambda = predictpoissonpar)
finalres <- mean(predictprob)
#paste("Mean probability for no bids on the new auction:",signif(finalres,3))
paste("Mean probability for no bids on the new auction:",sum(predictprob == 0)/10000)
```

We can tell that the coin object and the seller is of good quality, but that the MinBidShare and LogBook values were rather higher than average. We believe that the result is reasonable. 

